{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26f8977",
   "metadata": {},
   "source": [
    "### Imports and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623dda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61700c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_random_iid='./results/TestSuite-random_iid_06_15_2021.pkl'\n",
    "PATH_uniform_iid='./results/TestSuite-uniform_iid_06_16_2021.pkl'\n",
    "PATH_uniform_non_iid=\"./results/TestSuite-uniform_non_iid_06_17_2021.pkl\"\n",
    "PATH_random_non_iid=\"./results/TestSuite-random_non_iid_06_17_2021.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46882557",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ccf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    return data\n",
    "\n",
    "data_uniform_iid = load_pickle(PATH_uniform_iid)\n",
    "data_uniform_non_iid = load_pickle(PATH_uniform_non_iid)\n",
    "data_random_non_iid = load_pickle(PATH_random_non_iid)\n",
    "data_random_iid = load_pickle(PATH_random_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ecd9b2",
   "metadata": {},
   "source": [
    "### Helper functions for wrangling the data for the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d5ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of epochs it takes to converge and return a list of configuration + convergence epochs\n",
    "def get_convergence(results, epsilon = 0.0001, config = \"uniform_non_iid\"):\n",
    "    \n",
    "    setup = []\n",
    "    for idx, run in enumerate(results): # Iterate through runs\n",
    "\n",
    "        nr_nodes = run['nr_nodes']\n",
    "        run_epochs = []\n",
    "        run_test_acc = []\n",
    "        run_train_loss = []\n",
    "        \n",
    "        for i in range(nr_nodes): # Iterate through nodes in run\n",
    "            \n",
    "            node_dict = run[f'node_{i}']\n",
    "            train_acc = node_dict['train_accuracies']\n",
    "            train_loss = node_dict['train_losses']\n",
    "            test_acc = node_dict['test_accuracies']\n",
    "            learning_rate = node_dict['lr']\n",
    "            \n",
    "            for j in range(len(train_acc)-1): # Iterate through training accuracies\n",
    "                                \n",
    "                if abs(train_acc[j+1]-train_acc[j]) < epsilon:\n",
    "                    run_epochs.append(j+1)\n",
    "                    run_train_loss.append(train_loss[j])\n",
    "                    run_test_acc.append(test_acc[j])\n",
    "                    break\n",
    "                    \n",
    "                # If the run does not converge in the given number of epochs, we just take the accuracies of the last epoch     \n",
    "                elif j == len(train_acc)-2:\n",
    "                    run_epochs.append(j+2)\n",
    "                    run_train_loss.append(train_loss[j+1])\n",
    "                    run_test_acc.append(test_acc[j+1])\n",
    "            break\n",
    "\n",
    "        setup.append([run['add_privacy_list'], learning_rate, run['graph'], round(np.mean(run_epochs)), round(np.mean(run_train_loss),4), round(np.mean(run_test_acc),4), run['nr_nodes']])\n",
    "        \n",
    "    # Reformat list results into pandas dataframe\n",
    "    setup_df = pd.DataFrame(setup, columns = [\"Private\", \"Learning_rate\", \"Graph\", \"Mean_epochs\", \"Mean_train_loss\", \"Mean_test_accuracy\", \"Nr_nodes\"])\n",
    "    # Create the result table for the paper\n",
    "    setup_df = setup_df.sort_values(by=[\"Nr_nodes\", \"Private\"])\n",
    "    setup_df[\"Config\"] = config\n",
    "    cols = list(setup_df.columns)\n",
    "    cols = cols[-2:] + cols[:-2]  \n",
    "    setup_df = setup_df[cols]\n",
    "    setup_df = setup_df.replace(True, \" Private\")\n",
    "    setup_df = setup_df.replace(False, \" \")  \n",
    "    setup_df[\"Config\"] = setup_df[\"Config\"] + setup_df[\"Private\"]\n",
    "    setup_df = setup_df.drop(columns = \"Private\")\n",
    "    setup_df['Mean_epochs'] = setup_df['Mean_epochs'].apply(str)\n",
    "    \n",
    "    return setup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22acc43",
   "metadata": {},
   "source": [
    "### Create and save the tables for each setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138643f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_uniform_non_iid = get_convergence(data_uniform_non_iid, epsilon = 0.0001, config = \"Non-IID Uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_random_non_iid = get_convergence(data_random_non_iid, epsilon = 0.0001, config = \"Non-IID Random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f5683",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_uniform_iid = get_convergence(data_uniform_iid, epsilon = 0.0001, config = \"IID Uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_random_iid = get_convergence(data_random_iid, epsilon = 0.0001, config = \"IID Random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52431ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge all results\n",
    "results = results_uniform_iid.append(results_random_iid).append(results_uniform_non_iid).append(results_random_non_iid)\n",
    "results = results.sort_values(by = [\"Nr_nodes\", \"Config\"])\n",
    "results = results.replace(\"50\", \">50\")\n",
    "\n",
    "# Split results by number of nodes\n",
    "results_04 = results[results[\"Nr_nodes\"] == 4].drop(columns=\"Nr_nodes\").set_index([\"Config\",\"Learning_rate\"])\n",
    "results_16 = results[results[\"Nr_nodes\"] == 16].drop(columns=\"Nr_nodes\").set_index([\"Config\",\"Learning_rate\"])\n",
    "results_32 = results[results[\"Nr_nodes\"] == 32].drop(columns=\"Nr_nodes\").set_index([\"Config\",\"Learning_rate\"])\n",
    "\n",
    "# Save the tables as .tex\n",
    "results_04.to_latex(buf='./results_tables/4_epochs_table.tex', sparsify=True)\n",
    "results_16.to_latex(buf='./results_tables/16_epochs_table.tex', sparsify=True)\n",
    "results_32.to_latex(buf='./results_tables/32_epochs_table.tex', sparsify=True)\n",
    "\n",
    "results_04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}